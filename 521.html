<!-- saved from url=(0062)http://www.genome.duke.edu/labs/engelhardt/courses/sta521.html -->
<html><head><meta http-equiv="Content-Type" content="text/html;
                                                     charset=UTF-8"><title>STA521 Predictive Modeling and Statistical Learning, Fall 2020</title>
    <style type="text/css">
    </style>
</head>

<body bgcolor="#FFFFFF" text="#000000" link="#6633FF" vlink="#007f0f">

<h2 align="center">STA521: Predictive Modeling and Statistical Learning: Fall 2020</h2>
  
<table align="center">
<table align="center"> 

<tbody><td>Prof:</td><td><a href="http://www.stat.duke.edu/~sayan/">Sayan Mukherjee</a></td>
                 <td><a href="mailto:sayan@stat.duke.edu">
                 <i>sayan</i></a><i>@stat.duke.edu</i></td><td></td>
                 <td>OH: T/W/Th 1-2pm</td><td>https://duke.zoom.us/j/6247790803</td></tr>                 
<tr><td>TA:</td><td> Bo Liu  </td><td> bo.liu1997@duke.edu</td><td>OH:
    M 8-10pm
    </td><td></td><td></td></tr> 
<tr><td>Class:</td><td>T/TH 10:15-11:30am</td><td></td><td></td><td></td><td> </td></tr> 
<tr><td>Lab:</td><td>W 8:30-9:45am</td><td></td><td></td><td></td><td> </td></tr>   
</tbody></table>



<hr>
<h3 align="center">Description</h3>
An introduction to statistical learning methods for prediction and inference. This course introduces students to concepts and techniques of Classical and Bayesian approaches for modern regression and predictive modelling. The course will blend theory and application using a range of examples. Topics include exploratory data analysis and visualization, linear and generalized linear models, model selection, penalized estimation and shrinkage methods including Lasso, ridge regression and Bayesian regression, regression and classification based on decision trees, Bayesian Model Averaging and ensemble methods, and time permitting, robust estimation, smoothing splines, support vector machines, neural nets or other advanced topics. The R programming language and applications are used throughout. Corequisite: Statistical Science 323D or 523L and Statistical Science 360, 601, or 602L.HMMs,  MCMC. Emphasis is on applying these techniques to real data in a variety of application areas.
<p>
All students should be comfortable with linear/matrix algebra and mathematical statistics at the level of STA 611 (Statistical Inference - Casella and Berger is an excellent resource) and familiar with the R programming language and should be familiar with linear regression. Students should be familiar with Bayesian statistics either by taking the introduction to Bayesian inference STA 360/601/602 or currently co-registered in the course. Please see me if you have questions about the pre-requisites/background.
<p>


<hr>
<h3 align="center">Texts</h3>
The course will follow the texts and notes developed by Merlise Clyde,  <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/#projects"> Fall 2019</a>

Some texts that will be used throught the semester
</p><ol>
<li> An Introduction to Statistical Learning: with Applications in R. <a href="http://getitatduke.library.duke.edu/?sid=sersol&SS_jc=TC0000935811&title=An%20Introduction%20to%20Statistical%20Learning%20with%20Applications%20in%20R"> Freely available as an eBook</a>  
</li><li>Elements of Statistical Learning. <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">Freely available as an eBook</a>
</li><li>Applied Linear Regression. <a href="http://search.library.duke.edu/search?id=DUKE005781635" target="_blank">Freely available from get it @ Duke</a>
</li><li>Data Analysis Using Regression and  Multilevel/Hierarchical Models. <a href="https://www.amazon.com/Analysis-Regression-Multilevel-Hierarchical-Models/dp/052168689X/ref=sr_1_1_twi_pap_2?s=books&amp;ie=UTF8&amp;qid=1483554410&amp;sr=1-1&amp;keywords=9780521686891"> From Amazon</a> 
</li><li>A First Course in Bayesian Statistical Methods. <a href="http://getitatduke.library.duke.edu/?sid=sersol&amp;SS_jc=TC0000296463&amp;title=A%20First%20Course%20in%20Bayesian%20Statistical%20Methods">Freely avaialable as an eBook via Duke library</a>
  </li>
</ol>
<p>  

<p>Linear and matrix algebra will be used extensively, for a review or brush-up look at <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/#resources"> these resources</a>.
 
  
  
<hr>
<h3 align="center">Computation</h3>

<p>We will use R as a programming language for computation and data analysis, with the use existing packages written in R to support the course. All students will have access to RStudio/R on a server within the department and support during the labs. You are free to run RStudio/R on your personal laptop or desktop. </p> 

<p>There will also be some use of JAGS in this course for heirarchical modeling.</p>
  
<p>You will also need to be able to use git/github for you homeworks and downloading/adapting code.</p>  

<p>Beyond the resources on this page, feel free to look at <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/#resources"> these resources</a>.


<p><a href="http://www.r-project.org" target="_blank">R</a> is a statistical programming language that is especially powerful for data exploration, visualization, and statistical analysis. To interact with R (initially), we will primarily be using <a href="http://www.rstudio.com/" target="_blank">RStudio</a>, an interactive development environment (IDE).</p>

<p>We will mostly be using a browser based version of RStudio on a remote server but you can also install a local version of the <a href="http://www.rstudio.com/ide/download/desktop" target="_blank">RStudio IDE</a>.</p>
  
<p>Books &amp; Resources for learning R</p>

<ul>
<li><a href="https://www.codeschool.com/courses/try-r" target="_blank">Codeschool - Try R</a>  A brief R tutorial, in case you would like to have another avenue by which to get introduced to R.</li>
<li><a href="http://r4ds.had.co.nz" target="_blank">R for Data Science</a> - Grolemund, Wickham
O&rsquo;Reilly, 1st edition, 2016 (ISBN:)</li>
<li><a href="http://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/0387981403/ref=pd_sim_14_3?ie=UTF8&amp;refRID=0PWK3YY76N4T5G8KQRFF" target="_blank">ggplot2: Elegant Graphics for Data Analysis Use R! Buy it at
Amazon</a></li>
<li><a href="http://adv-r.had.co.nz" target="_blank">Advanced R</a> - H. Wickham
Chapman and Hall/CRC, 1st edition, 2014 (ISBN: 978-1466586963)</li>
<li><a href="http://r-pkgs.had.co.nz" target="_blank">R Packages</a> - H Wickham
O&rsquo;Reilly, 1st edition, 2015 (ISBN: 978-1491910597)
*<a href="https://www.r-project.org" target="_blank">The R Project for Statistical Computing</a></li>
<li><a href="http://archive.linux.duke.edu/cran/" target="_blank">R Downloads</a> Duke Mirror with Linux, Mac, Windows</li>
<li><a href="https://www.rstudio.com" target="_blank">Rstudio</a> Easy user interface for R/R Markdown and more for Linux, Mac and Windows  <a href="https://www.rstudio.com/products/RStudio/" target="_blank">Download</a></li>
<li><a href="https://cran.r-project.org/doc/manuals/R-intro.pdf" target="_blank">An Introduction to R (pdf)</a>  <a href="https://cran.r-project.org/doc/manuals/R-intro.html" target="_blank">(html version)</a> the most up-to-date official R intro</li>
<li><a href="http://www.twotorials.com/" target="_blank">twotorials</a>: how to do stuff in r. two minutes or less.</li>
</ul>



<p>JAGS is Just Another Gibbs Sampler.  It is a program for analysis of Bayesian hierarchical models using Markov Chain Monte Carlo (MCMC)
simulation  not wholly unlike BUGS. The name is a misnomer as JAGS implements more than just Gibbs Samplers.
JAGS was written with three aims in mind:</p>

<ul>
<li>To have a cross-platform engine for the BUGS language</li>
<li>To be extensible, allowing users to write their own functions, distributions and samplers.</li>
<li>To be a plaftorm for experimentation with ideas in Bayesian modelling</li>
</ul>

<p>Resources for JAGS:</p>

<ul>
<li><a href="http://mcmc-jags.sourceforge.net" target="_blank">JAGS website on Sourceforge for Downloads, Manuals, etc</a></li>
<li><a href="https://martynplummer.wordpress.com" target="_blank">JAGS News</a>  Martin Plummer&rsquo;s</li>
<li>site for all things JAGS</li>
<li><a href="https://cran.r-project.org/web/packages/rjags/" target="_blank">rjags on CRAN</a></li>
</ul>



<p>Git is a state-of-the-art version control system. It lets you track who made changes to what when and has options for easily updating a shared or public version of your code on <a href="https://github.com/" target="_blank">github</a>.</p>

<ul>
<li><p>OSX - install Git for Mac by downloading and running <a href="http://git-scm.com/downloads" target="_blank">the installer</a> or install <a href="http://brew.sh/" target="_blank">homebrew</a> and use it to install git via <code>brew install git</code>.</p></li>

<li><p>Unix/Linux - you should be able to install git via your prefered package manager (if it is not already installed).</p></li>

<li><p>Windows - install Git for Windows by download and running the git for windows <a href="http://msysgit.github.io/" target="_blank">installer</a>. This will provide you with git, the bash shell, and ssh in windows.</p></li>

<li><p><a href="http://www2.stat.duke.edu/~cr173/Sta523_Fa16/" target="_blank">Screencasts from STA523</a> will be helpful in refreshing/learning how
to use git and github</p></li>
</ul>  
  
  
 

There is a <a href="https://piazza.com/duke/spring2020/sta561">Piazza</a> course
discussion page. Please direct questions about homeworks and other
matters to that page. Otherwise, you can email the instructors (TAs
and professor). Note that we are more likely to
respond to the Piazza questions than to the email, and your classmates
may respond too, so that is a good place to start.

<hr>
<h3 align="center">Syllabus</h3>

<h3 id="course-goals-objectives">Course goals &amp; objectives:</h3>

<p>This course introduces students to concepts and techniques of
Classical and Bayesian approaches for modern regression and predictive
modelling.  The course will blend theory and application using a range
of examples.</p>

<p>It is expected that students have either taken STA 601 (STA 360 or STA602L or equivalent),
are co-registed, or are familiar with some basics of Bayesian
analysis!  We will introduce JAGS to simplify modelling and use a
range of R packages to support computing.</p>

<p>All students should be comfortable with
mathematical statistics at the level of STA 250 or STA611. Linear algebra
and basics of linear regression are also considered
prerequisite.</p>



<b>Course goals & objectives:</b> <br>
This course introduces students to concepts and techniques of Classical and Bayesian approaches for modern regression and predictive modelling. The course will blend theory and application using a range of examples.

<br>It is expected that students have either taken STA 601 (STA 360 or STA602L or equivalent), are co-registed, or are familiar with some basics of Bayesian analysis! We will introduce JAGS to simplify modelling and use a range of R packages to support computing.
<br>All students should be comfortable with mathematical statistics at the level of STA 250 or STA611. Linear algebra and basics of linear regression are also considered prerequisite. 
<br> 




<hr>
<h3 align="center">Course schedule</h3>




This schedule is <i>tentative</i>, and will almost surely be modified. Reload your browser for the current version.
</p><p>

</p><ol>
  <li> (Aug 18th) Course introduction: <a href="sayanmuk.github.io/Lecture 1.htm">Lecture</a> <br>
  Course overview and introduction to statistical learning and predictive inference. Read Chapter 1 of ISLR</li>
<!--<ul>
<li> Optional: (video) Christopher Bishop <a href="http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739">Embracing Uncertainty: The New Machine Intelligence</a></li>
<li> Optional: (video) Sam
  Roweis <a href="http://videolectures.net/mlss06tw_roweis_mlpgm/">Machine
    Learning, Probability and Graphical Models, Part 1</a></li>
<li> Optional: (video) Mikaela
  Keller <a href="http://videolectures.net/bootcamp07_keller_bss/">
  Basics of probability and statistics for statistical
  learning</a></li>
<li> Optional: Alan
  Turing <a href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">Computing  Machinery and Intelligence</a></li>
</ul></li>
</ul>-->
  <br>
 <li> (Aug 20th) Modelling Overview and Review of Regression: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-2-Models/Models.pdf">Lecture</a> <br>
  Justification of models and review of linear regression. Read Chapter 2-3 of Elements of Statistical Learning or Chapters 2-3 ISLR
  <br>Homework 1: Complete the problems in the github repo for <a href="https://github.com/sta521-f19/HW1"> HW 1</a>
<br>1) Login to saxon and Rstudio <a href="https://saxon.stat.duke.edu:8787"> https://saxon.stat.duke.edu:8787</a> or use your local computer.
<br>2) Create an a new project in RStudio (see lab1 instructions) and clone the repo using the link <a href="http://github.com/sta521-f19/HW1.git">http://github.com/sta521-f19/HW1.git</a>
<br>3) Work the problems in HW1.Rmd (applied and theory)
<br>4) Upload your Rmd file and a pdf to Sakai under assignments by Aug 28 10 am.
  </li>
<!--<ul>
<li> Optional: (video) Christopher Bishop <a href="http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739">Embracing Uncertainty: The New Machine Intelligence</a></li>
<li> Optional: (video) Sam
  Roweis <a href="http://videolectures.net/mlss06tw_roweis_mlpgm/">Machine
    Learning, Probability and Graphical Models, Part 1</a></li>
<li> Optional: (video) Mikaela
  Keller <a href="http://videolectures.net/bootcamp07_keller_bss/">
  Basics of probability and statistics for statistical
  learning</a></li>
<li> Optional: Alan
  Turing <a href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">Computing  Machinery and Intelligence</a></li>
</ul></li>
</ul>-->
<br>
 <li> (Aug 25th) Diagnostics: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-3-Diagnostics/Diagnostics.pdf">Lecture</a> <br>
  Regression diagnostics for linear regression. Read ALR Ch 9 or ALR Chapter 9 (4th Edition) and Computing Primer for ALR
</li>
<!--<ul>
<li> Optional: (video) Christopher Bishop <a href="http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739">Embracing Uncertainty: The New Machine Intelligence</a></li>
<li> Optional: (video) Sam
  Roweis <a href="http://videolectures.net/mlss06tw_roweis_mlpgm/">Machine
    Learning, Probability and Graphical Models, Part 1</a></li>
<li> Optional: (video) Mikaela
  Keller <a href="http://videolectures.net/bootcamp07_keller_bss/">
  Basics of probability and statistics for statistical
  learning</a></li>
<li> Optional: Alan
  Turing <a href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">Computing  Machinery and Intelligence</a></li>
</ul></li>
</ul>-->
<br>
(Aug 26th) Lab 1: <a href="https://github.com/STA521-F19/Lab1">RStudio, Git, & Reproducible EDA using Rmarkdown</a> 
<br>
Homework 2: This is an individual assignment using Github Classroom.  To create your repo for the assignment.<br>
Please see the link in Sakai to the GitHub classroom invitation for the assignment
<br>1) You will be asked to identify your email on the roster  - please do so if you have not already. While the instruction say you can skip this step, please do not. This will link your github username to the roster. We will need that for creating team assignments later.
<br>2) Click on the “accept” button.
<br>3) After the repo is created it will show a link to your repo in the @sta521-F19 organization; click on the link and get started with the instructions in the README file and see the Rmd file.
<br>4) Upload your Rmd file and a pdf to Sakai under assignments by Sept 4 10 am.
<br> 
Please push your final Rmd file and pdf file to the organization repo from your local repo by Sept 4. You should also upload your Rmd and pdf onto Sakai.
<br>   
  <br>  
 <li> (Aug 27th) Transformations:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-4-Transformations/Transformations.pdf">Lecture</a><br>
Influence and Transformations. Read ALR Chapter 8-9 and the Appendix A.12 (4th Edition) and Computing Primer for ALR
</li>
<br>  
 <li> (Sept 1st) Interpretation, Prediction Intervals and Added-Variable Plots:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-6-Interpretation/Interpretation.pdf">Lecture</a><br>
Interpretation, Prediction Intervals and Added-Variable Plots. Read ALR Chapter 3-4 and Computing Primer for ALR.
</li>  
<br>
(Sept 2nd) Lab 2: Using github and github classroom with RStudio<br>
<br>    
 <li> (Sept 3rd) Logistic Regression:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-7-Binary-Regression/logistic.pdf">Lecture</a><br>
Binary Regression. Read ESL and/or ISLR Chapter 4 and ALR Chapter 12, GH Chapter 5 for binned plots.
In this lecture, we will describe the use of binary regression when the response variable is binary.
<br>Homework 3: Description on Sakai.
<br>1) This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW3 (same teams as lab). Please work together on the assignment to complete all parts.
<br>2) Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment.
 <br>3) You should also upload your Rmd and pdf onto Sakai (one per group).
<br>4) Upload your Rmd file and a pdf to Sakai under assignments by Sept 11 10 am.
  </li>
</li>  
<br>
<li> (Sept 8th) Logistic Regression and Analysis of Deviance:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-8-Analysis-of-Deviance/deviance.pdf">Lecture</a><br>
Analysis of Deviance in Logistic Regression. Read ESL and/or ISLR Chapter 4 and ALR Chapter 12, GH Chapter 5 for binned plots.
In this lecture, we will describe the use of binary regression when the response variable is binary.
  </li>
<br>
(Sept 9th) Lab 4: Logistic Regression, Werker, Teams, and Q&A. Read lab 4 on Sakai for details.
<br>
<br>
<li> (Sept 10th) Modeling Count Data: Poisson & Negative Binomial Models: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-9-Poisson/Poisson.pdf">Lecture</a><br>
In this lecture, we will explore Poisson and Negative Binomial regression for modeling count data.<br>
<br>Homework 4: Description on Sakai.  
<br>This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW4 (same teams as lab). Please work together on the assignment to complete all parts.
<br>Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment (3 points).
<br>You should also upload your Rmd and pdf onto Sakai (one per group) by Sept 18 10 am.  
</li>
<br>
<li> (Sept 15th) Negative Binomial Models and Predictive Checks: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-10-NegativeBinomial/negative-binomial.pdf">Lecture</a><br>
Negative Binomial Regression and Predictive Checks. Read GH Chapter 6-8. In this lecture, we will explore Poisson and Negative Binomial regression for modeling count data and explore simulation methods to check for model fit.
</li>
 <br>
(Sept 16th) Lab 5: Predictive Checks & Simulation. Read lab 5 on Sakai for details.
<br>
<br>
<li> (Sept 17th) Model Selection:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-11-Model-Selection/Selection.pdf">Lecture</a>
<br>Model Selection. ISLR Ch 6. ESL Ch 7; Read GH Chapter 6-8. In this lecture, we will introduce AIC and BIC as criteria for selecting models and look at several algorithms for finding the the best model.
</li>
<br>
<li> (Sept 22nd) Cross-Validation:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-12-Resampling/Resampling.pdf">Lecture</a>
<br>Model Assessment and Selection: Resampling ISLR Ch 6. Read GH Chapter 6-8. In this lecture, we will continue to explore model selection using resampling methods to estimate prediction error.
</li>
<br>
(Sept 23rd) Midterm I. Two hour take-home exam on Sakai.
<br>
<br>
<li> (Sept 24th) Coverage:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-12-Resampling/Resampling.pdf">Lecture</a>
<br>Model Assessment and Selection: Resampling ISLR Ch 6. Read GH Chapter 6-8. In this lecture, we will continue to explore model selection using resampling methods to estimate prediction error.
</li>
<br>
<li> (Sept 29th) Bayesian Regression:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-13-Bayes-Reg/bayesreg.pdf">Lecture</a>
<br>Bayesian Regression - Hoff Chapter 9. In this lecture, we will introduce Bayesian methods for estimation in linear regression.
</li>
<br>
(Sept 30th) Lab 6: Simulating Coverage plus Q&A. Read lab 6 on Sakai for details.
<br>
<br>
<li> (Oct 1st) Priors in Bayesian Regression:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-14-Priors/priors.pdf">Lecture</a>
<br>Priors in Bayesian Regression - Hoff Chapter 9. In this lecture, we will introduce Bayesian methods for estimation in linear regression under conjugate priors. We will introduce Jeffreys reference priors and the Zellner g-prior as two default choices.
<br>Homework 5: Description on Sakai.
<br>This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW5 (same teams as lab). Please work together on the assignment to complete all parts.
<br> Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment.
<br> You should also upload your Rmd and pdf onto Sakai (one per group) by Oct 9 10am.  
</li>
<br>
<li> (Oct 6th) Bayesian Variable Selection:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-15-Bayes-VarSel/bayes-varsel.pdf">Lecture</a>
<br>Bayesian Variable Selection - Hoff Chapter 9. In this lecture, we will introduce Bayesian methods for variable selection in linear regression under the g-prior.
</li>
<br>
(Oct 7th) Lab Q&A. 
<br>
<br>
<li> (Oct 8th) Bayesian Model Averaging:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-16-BMA/bma.pdf">Lecture</a>
<br>Bayesian Model Averaging. In this lecture, we will introduce Bayesian Model Averaging. Rather than selecting a single model for inference, we will use an ensemble of models, weighted by their posterior probabilities.
Supplemental Readings: Chapters 6-8: Introduction to Bayesian Thinking.
 </li>
<br>
<li> (Oct 13th) Ridge Regression
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-17-Ridge/ridge.pdf">Lecture</a>
<br>Ridge Regression. In this lecture, we will introduce Ridge regression from frequentist and Bayesian perspectives as a shrinkage estimator.
<br>Homework 6: Description on Sakai.
<br>This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW5 (same teams as lab). Please work together on the assignment to complete all parts.
<br> Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment.
<br> You should also upload your Rmd and pdf onto Sakai (one per group) by Oct 23 10am.  
</li>   
<br>
(Oct 14th) Lab 7: Variable Selection and Bayesian model averaging. Read lab 7 on Sakai for details.
<br>
<br>
<li> (Oct 15th) Shrinkage Estimators
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-17-Ridge/ridge.pdf">Lecture</a>
<br>Lasso and Bayesian Lasso. Lasso and Bayesian lasso Regression. In this lecture, we will introduce Lasso regression from frequentist and Bayesian perspectives as a shrinkage estimator.
</li>   
</body></html>
