<!-- saved from url=(0062)http://www.genome.duke.edu/labs/engelhardt/courses/sta521.html -->
<html><head><meta http-equiv="Content-Type" content="text/html;
                                                     charset=UTF-8"><title>STA521 Predictive Modeling and Statistical Learning, Fall 2020</title>
    <style type="text/css">
    </style>
</head>

<body bgcolor="#FFFFFF" text="#000000" link="#6633FF" vlink="#007f0f">

<h2 align="center">STA521: Predictive Modeling and Statistical Learning: Fall 2020</h2>
  
<table align="center">
<table align="center"> 

<tbody><td>Prof:</td><td><a href="http://www.stat.duke.edu/~sayan/">Sayan Mukherjee</a></td>
                 <td><a href="mailto:sayan@stat.duke.edu">
                 <i>sayan</i></a><i>@stat.duke.edu</i></td><td></td>
                 <td>OH: T/W/Th 1-2pm</td><td>https://duke.zoom.us/j/6247790803</td></tr>                 
<tr><td>TA:</td><td> Bo Liu  </td><td> bo.liu1997@duke.edu</td><td>OH:
    M 8-10pm
    </td><td></td><td></td></tr> 
<tr><td>Class:</td><td>T/TH 10:15-11:30am</td><td></td><td></td><td></td><td> </td></tr> 
<tr><td>Lab:</td><td>W 8:30-9:45am</td><td></td><td></td><td></td><td> </td></tr>   
</tbody></table>



<hr>
<h3 align="center">Description</h3>
An introduction to statistical learning methods for prediction and inference. This course introduces students to concepts and techniques of Classical and Bayesian approaches for modern regression and predictive modelling. The course will blend theory and application using a range of examples. Topics include exploratory data analysis and visualization, linear and generalized linear models, model selection, penalized estimation and shrinkage methods including Lasso, ridge regression and Bayesian regression, regression and classification based on decision trees, Bayesian Model Averaging and ensemble methods, and time permitting, robust estimation, smoothing splines, support vector machines, neural nets or other advanced topics. The R programming language and applications are used throughout. Corequisite: Statistical Science 323D or 523L and Statistical Science 360, 601, or 602L.HMMs,  MCMC. Emphasis is on applying these techniques to real data in a variety of application areas.
<p>
All students should be comfortable with linear/matrix algebra and mathematical statistics at the level of STA 611 (Statistical Inference - Casella and Berger is an excellent resource) and familiar with the R programming language and should be familiar with linear regression. Students should be familiar with Bayesian statistics either by taking the introduction to Bayesian inference STA 360/601/602 or currently co-registered in the course. Please see me if you have questions about the pre-requisites/background.
<p>


<hr>
<h3 align="center">Texts</h3>
The course will follow the texts and notes developed by Merlise Clyde,  <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/#projects"> Fall 2019</a>

Some texts that will be used throught the semester
</p><ol>
<li> An Introduction to Statistical Learning: with Applications in R. <a href="http://getitatduke.library.duke.edu/?sid=sersol&SS_jc=TC0000935811&title=An%20Introduction%20to%20Statistical%20Learning%20with%20Applications%20in%20R"> Freely available as an eBook</a>  
</li><li>Elements of Statistical Learning. <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">Freely available as an eBook</a>
</li><li>Applied Linear Regression. <a href="http://search.library.duke.edu/search?id=DUKE005781635" target="_blank">Freely available from get it @ Duke</a>
</li><li>Data Analysis Using Regression and  Multilevel/Hierarchical Models. <a href="https://www.amazon.com/Analysis-Regression-Multilevel-Hierarchical-Models/dp/052168689X/ref=sr_1_1_twi_pap_2?s=books&amp;ie=UTF8&amp;qid=1483554410&amp;sr=1-1&amp;keywords=9780521686891"> From Amazon</a> 
</li><li>A First Course in Bayesian Statistical Methods. <a href="http://getitatduke.library.duke.edu/?sid=sersol&amp;SS_jc=TC0000296463&amp;title=A%20First%20Course%20in%20Bayesian%20Statistical%20Methods">Freely avaialable as an eBook via Duke library</a>
  </li>
</ol>
<p>  

<p>Linear and matrix algebra will be used extensively, for a review or brush-up look at <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/#resources"> these resources</a>.
 
  
  
<hr>
<h3 align="center">Computation</h3>

<p>We will use R as a programming language for computation and data analysis, with the use existing packages written in R to support the course. All students will have access to RStudio/R on a server within the department and support during the labs. You are free to run RStudio/R on your personal laptop or desktop. </p> 

<p>There will also be some use of JAGS in this course for heirarchical modeling.</p>
  
<p>You will also need to be able to use git/github for you homeworks and downloading/adapting code.</p>  

<p>Beyond the resources on this page, feel free to look at <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/#resources"> these resources</a>.


<p><a href="http://www.r-project.org" target="_blank">R</a> is a statistical programming language that is especially powerful for data exploration, visualization, and statistical analysis. To interact with R (initially), we will primarily be using <a href="http://www.rstudio.com/" target="_blank">RStudio</a>, an interactive development environment (IDE).</p>

<p>We will mostly be using a browser based version of RStudio on a remote server but you can also install a local version of the <a href="http://www.rstudio.com/ide/download/desktop" target="_blank">RStudio IDE</a>.</p>
  
<p>Books &amp; Resources for learning R</p>

<ul>
<li><a href="https://www.codeschool.com/courses/try-r" target="_blank">Codeschool - Try R</a>  A brief R tutorial, in case you would like to have another avenue by which to get introduced to R.</li>
<li><a href="http://r4ds.had.co.nz" target="_blank">R for Data Science</a> - Grolemund, Wickham
O&rsquo;Reilly, 1st edition, 2016 (ISBN:)</li>
<li><a href="http://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/0387981403/ref=pd_sim_14_3?ie=UTF8&amp;refRID=0PWK3YY76N4T5G8KQRFF" target="_blank">ggplot2: Elegant Graphics for Data Analysis Use R! Buy it at
Amazon</a></li>
<li><a href="http://adv-r.had.co.nz" target="_blank">Advanced R</a> - H. Wickham
Chapman and Hall/CRC, 1st edition, 2014 (ISBN: 978-1466586963)</li>
<li><a href="http://r-pkgs.had.co.nz" target="_blank">R Packages</a> - H Wickham
O&rsquo;Reilly, 1st edition, 2015 (ISBN: 978-1491910597)
*<a href="https://www.r-project.org" target="_blank">The R Project for Statistical Computing</a></li>
<li><a href="http://archive.linux.duke.edu/cran/" target="_blank">R Downloads</a> Duke Mirror with Linux, Mac, Windows</li>
<li><a href="https://www.rstudio.com" target="_blank">Rstudio</a> Easy user interface for R/R Markdown and more for Linux, Mac and Windows  <a href="https://www.rstudio.com/products/RStudio/" target="_blank">Download</a></li>
<li><a href="https://cran.r-project.org/doc/manuals/R-intro.pdf" target="_blank">An Introduction to R (pdf)</a>  <a href="https://cran.r-project.org/doc/manuals/R-intro.html" target="_blank">(html version)</a> the most up-to-date official R intro</li>
<li><a href="http://www.twotorials.com/" target="_blank">twotorials</a>: how to do stuff in r. two minutes or less.</li>
</ul>



<p>JAGS is Just Another Gibbs Sampler.  It is a program for analysis of Bayesian hierarchical models using Markov Chain Monte Carlo (MCMC)
simulation  not wholly unlike BUGS. The name is a misnomer as JAGS implements more than just Gibbs Samplers.
JAGS was written with three aims in mind:</p>

<ul>
<li>To have a cross-platform engine for the BUGS language</li>
<li>To be extensible, allowing users to write their own functions, distributions and samplers.</li>
<li>To be a plaftorm for experimentation with ideas in Bayesian modelling</li>
</ul>

<p>Resources for JAGS:</p>

<ul>
<li><a href="http://mcmc-jags.sourceforge.net" target="_blank">JAGS website on Sourceforge for Downloads, Manuals, etc</a></li>
<li><a href="https://martynplummer.wordpress.com" target="_blank">JAGS News</a>  Martin Plummer&rsquo;s</li>
<li>site for all things JAGS</li>
<li><a href="https://cran.r-project.org/web/packages/rjags/" target="_blank">rjags on CRAN</a></li>
</ul>



<p>Git is a state-of-the-art version control system. It lets you track who made changes to what when and has options for easily updating a shared or public version of your code on <a href="https://github.com/" target="_blank">github</a>.</p>

<ul>
<li><p>OSX - install Git for Mac by downloading and running <a href="http://git-scm.com/downloads" target="_blank">the installer</a> or install <a href="http://brew.sh/" target="_blank">homebrew</a> and use it to install git via <code>brew install git</code>.</p></li>

<li><p>Unix/Linux - you should be able to install git via your prefered package manager (if it is not already installed).</p></li>

<li><p>Windows - install Git for Windows by download and running the git for windows <a href="http://msysgit.github.io/" target="_blank">installer</a>. This will provide you with git, the bash shell, and ssh in windows.</p></li>

<li><p><a href="http://www2.stat.duke.edu/~cr173/Sta523_Fa16/" target="_blank">Screencasts from STA523</a> will be helpful in refreshing/learning how
to use git and github</p></li>
</ul>  
  
  
 

<hr>
<h3 align="center">Syllabus</h3>

<h3 id="course-goals-objectives">Course goals &amp; objectives:</h3>

<p>This course introduces students to concepts and techniques of
Classical and Bayesian approaches for modern regression and predictive
modelling.  The course will blend theory and application using a range
of examples.</p>

<p>It is expected that students have either taken STA 601 (STA 360 or STA602L or equivalent),
are co-registed, or are familiar with some basics of Bayesian
analysis!  We will introduce JAGS to simplify modelling and use a
range of R packages to support computing.</p>

<p>All students should be comfortable with
mathematical statistics at the level of STA 250 or STA611. Linear algebra
and basics of linear regression are also considered
prerequisite.</p>

<p>The course goals are as follows:</p>

<ol>
<li>Understand the different philosophical approaches to prediction and
statistical inference (Bayesian and frequentists)</li>
<li>Build a solid foundation for the statistical theory for predictive
modelling and inference</li>
<li>Build appropriate statistical models,
perform data analysis using appropriate software, and communicate
results without use of statistical jargon using reproducible methods.</li>
<li>Use of simulation to characterize properties
of statistical methods.</li>
</ol>

<h4 id="topics">Topics</h4>

<p>Course topics will be drawn (but subject to change) from</p>

<ul>
<li>Introduction to Statistical Learning</li>
<li>Exploratory Data Analysis</li>
<li>Multiple Regression</li>
<li>Residual Analysis &amp; Model Checking</li>
<li>Bayesian Regression</li>
<li>Outliers and Robust Regression</li>
<li>Model Selection and Bayesian Model Averaging</li>
<li>Shrinkage and Hierarchical Models</li>
<li>Models for Count Data (Poisson Regression)</li>
<li>Logistic Regression and Classification</li>
<li>Classification and Regression Trees (and Forests)</li>
<li>Generalized Additive Models</li>
<li>Bayesian Nonparametric Regression</li>
<li>Ensemble Methods</li>
<li>Decision and Inference in Modern Regression</li>
</ul>



<h3 id="grading">Grading:</h3>

<div style="padding-left:2em;padding-top:1em;">
<table style="width:400px;">
<tr> <td> Homework              </td> <td> 25% </td></tr>
<tr> <td> Midterm I        </td> <td> 20% </td></tr>
<tr> <td> Midterm II         </td> <td> 20% </td></tr>
<tr> <td> Data Analysis Project Part I  </td> <td> 15% </td></tr>
<tr> <td> Data Analysis Project Part II  </td> <td> 15% </td></tr>
<tr> <td> Participation        </td> <td> 5% </td></tr>

</table>
</div>

<p>Grades may be curved at the end of the semester. Cumulative numerical averages of 90 - 100 are guaranteed at least an A-, 80 - 89 at least a B-, and 70 - 79 at least a C-, however the exact ranges for letter grades will be determined after the final exam. The more evidence there is that the class has mastered the material, the more generous the curve will be.</p>



<h3 id="statistical-analysis">Statistical Analysis:</h3>

<p>We will use R as a programming language for data analysis and use
  existing packages written in R to support the course in addition to
  Bayesian computation using JAGS.  We will  provide access
  to a dedicated server running RStudio Pro so that  all students  will
  have a unified environment. You may wish to install R and
  RStudio to run code on your own desktop or laptop.  We will cover instruction of R in the labs/class.</p>

<h3 id="homework">Homework:</h3>

<p>The objective of the problem sets is to help you develop a more in-depth understanding of the material and help you prepare for exams and projects. Grading will be based on completeness as well as accuracy.
The assignments  will be a mix of individual and coding team based
assignments.</p>

<p><strong>Submission instructions:</strong> You will submit your HW on Sakai by
  uploading a PDF or through the Course Organization repo on
  github for your team.</p>

<p>All assignments will be time stamped and late work will be penalized based on this time stamp (see late work policy below).</p>

<ul>
<li><p>Missed/Late work policy for Homework:</p>

<ul>
<li>No Late HW</li>
<li>We will drop the lowest Homework Score</li>
</ul></li>

<li><p>Regrade requests must be made <strong>within 3 days</strong> of when the
assignment is returned, and must be submitted in writing. These will
be honored if points were tallied incorrectly, or if you feel your
answer is correct but it was marked wrong. No regrade will be made
to alter the number of points deducted for a mistake. There will be
no grade changes after the final exam for Homework.</p></li>
</ul>



<h3 id="final-data-analysis-project">Final Data Analysis Project</h3>

<p>The objective of the Project is to give you real-world
research experience using real data and statistical methods.  You will
use all (relevant) techniques learned in this class or explore
additional advanced material to solve a problem, explore its
properties (either analytically or through simulation) and present it
using reporducible methods.</p>

<p>Further details  will be provided as due dates approach.</p>



<h3 id="exams">Exams:</h3>

<p>There will be two midterms. See the Course Schedule for dates and times of the exams. The exam is closed book
 and you are allowed to use one sheet of notes (``cheat sheet&rdquo;) for each
exam. This sheet must be no larger than 8 <sup>1</sup>&frasl;<sub>2</sub> x 11,
and <strong>must be prepared by you</strong>. You may use both sides of the sheet
and can write as small as you wish.</p>

<h4 id="missed-exams">Missed Exams</h4>

<p>There will be no makeup exams.  If a student misses one exam for any
reason, their score will be imputed based on the previous or future
exam.  Missing both exams will result in a grade of 0 on the exams.</p>

<h4 id="a-name-exams-a-key-dates"><a name="exams"></a>Key Dates:</h4>

<p>See the Course Schedule for dates for the Midterms and other
assignments.  If MSS students have more than 3 exams in one week,
please notify me as soon as possible, so that we may adjust timing if
possible as early in the semester as possible.</p>

<p>The Final Exam Slot, listed in the Course Calendar, will be used for final presentations of the Data Analysis Project.</p>



<h3 id="attendance-participation">Attendance &amp; Participation:</h3>

<p>You are expected to be present at class meeting and actively participate in the discussion. Your attendance and participation
during class, as well as your activity on the discussion forum on piazza, commits on github, as well as participation questions 
(this will be descibed as the semester progresses) will make up 5% of your grade in this class. 
  .</p>



<h3 id="email-forum-piazza">Email &amp; Forum (Piazza):</h3>

<p>We will be using
<a href="https://piazza.com/duke/fall2018/sta52101f20/home" target="_blank">Piazza</a> for class
discussion. The system is highly catered to getting you help fast and
efficiently from classmates, the TA, and myself. Rather than emailing
questions to the teaching staff, I encourage you to post your
questions on Piazza (peer answers earn participation points!). If you
have any problems or feedback for the developers, email
team@piazza.com.</p>

<p>Any non-personal questions related to the material covered in class,
problem sets, labs, projects, etc. should be posted on Piazza.
Before posting a new question please make sure to check if your
question has already been answered. The TAs and myself will be
answering questions on the forum daily and all students are expected
to answer questions as well as part of the participation grade. Please
use informative titles for your posts and link to the appropriate topics.</p>

<p>Note that it is sometimes more efficient to answer statistical questions ``in person&rdquo; so please make use of Office Hours.</p>



<h3 id="students-with-disabilities">Students with disabilities:</h3>

<p>Students with disabilities who believe they may need accommodations in this class are encouraged to contact the <a href="http://www.access.duke.edu/students/requesting/index.php" target="_blank">Student Disability Access Office</a> at (919) 668-1267 as soon as possible to better ensure that such accommodations can be made.</p>



<h3 id="academic-integrity">Academic integrity:</h3>

<p>Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, respect, and accountability. Citizens of this community commit to reflect upon and uphold these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity. Cheating on exams and quizzes, plagiarism on homework assignments and projects, lying about an illness or absence and other forms of academic dishonesty are a breach of trust with classmates and faculty, violate the <a href="http://www.studentaffairs.duke.edu/conduct/resources/dcs" target="_blank">Duke Community Standard</a>, and will not be tolerated. Such incidences will result in a 0 grade for all parties involved as well as being reported to the <a href="http://www.studentaffairs.duke.edu/conduct" target="_blank">Office of Student Conduct</a>. Additionally, there may be penalties to your final class grade. Please review the <a href="http://www.studentaffairs.duke.edu/conduct/resources/academicdishonesty" target="_blank">Duke&rsquo;s Academic Dishonesty policies</a>.</p>
<br>
<br>




<hr>
<h3 align="center">Course schedule</h3>




This schedule is <i>tentative</i>, and will almost surely be modified. Reload your browser for the current version.
</p><p>

</p><ol>
  <li> (Aug 18th) Course introduction: <a href="sayanmuk.github.io/Lecture 1.htm">Lecture</a> <br>
  Course overview and introduction to statistical learning and predictive inference. Read Chapter 1 of ISLR</li>
<ul>
<li> Zoom lecture: <a href="https://duke.zoom.us/rec/share/4ZJRDq3PzF1IWp3qsmX2ZYVmOI_Oaaa8h3VP8vJYmhtQAp9PH5JUSR5S34fABERL"> Lecture 1
</a></li>  
<li> Optional: Leo Brieman <a href="https://projecteuclid.org/euclid.ss/1009213726">Statistical Modeling: The Two Cultures</a></li>
<li> Optional: David Donoho <a href="https://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf"> 50 Years of Data Science</a></li>
</ul>
  <br>
 <li> (Aug 20th) Modelling Overview and Review of Regression: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-2-Models/Models.pdf">Lecture</a> <br>
  Justification of models and review of linear regression. Read Chapter 2-3 of Elements of Statistical Learning or Chapters 2-3 ISLR</li>
<ul>
<li> Zoom lecture: <a href="https://duke.zoom.us/rec/share/6shUdbTbrlpJTp3d5GGDVZ94PNraeaa8gycar_MJzkm7NoSt0wF4tsrS4AjpStX_"> Lecture 2
</a></li>  
<li> Homework 1: Complete the problems in the github repo for <a href="https://github.com/sta521-f19/HW1"> HW 1</a>
<br>1) Login to saxon and Rstudio <a href="https://saxon.stat.duke.edu:8787"> https://saxon.stat.duke.edu:8787</a> or use your local computer.
<br>2) Create an a new project in RStudio (see lab1 instructions) and clone the repo using the link <a href="http://github.com/sta521-f19/HW1.git">http://github.com/sta521-f19/HW1.git</a>
<br>3) Work the problems in HW1.Rmd (applied and theory)
<br>4) Upload your Rmd file and a pdf to Sakai under assignments by Aug 28 10 am.
  </li>
  </ul>
<!--<ul>
<li> Optional: (video) Christopher Bishop <a href="http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739">Embracing Uncertainty: The New Machine Intelligence</a></li>
<li> Optional: (video) Sam
  Roweis <a href="http://videolectures.net/mlss06tw_roweis_mlpgm/">Machine
    Learning, Probability and Graphical Models, Part 1</a></li>
<li> Optional: (video) Mikaela
  Keller <a href="http://videolectures.net/bootcamp07_keller_bss/">
  Basics of probability and statistics for statistical
  learning</a></li>
<li> Optional: Alan
  Turing <a href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">Computing  Machinery and Intelligence</a></li>
</ul></li>
</ul>-->
<br>
 <li> (Aug 25th) Diagnostics: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-3-Diagnostics/Diagnostics.pdf">Lecture</a> <br>
  Regression diagnostics for linear regression. Read ALR Ch 9 or ALR Chapter 9 (4th Edition) and Computing Primer for ALR
</li>
<ul>
<li> Zoom lecture: <a href="https://duke.zoom.us/rec/share/6pxtIpDP73pIZKfq0WbnBocNBtn6T6a80ChMqfoKy0rI8RpV52ZtGzttg0KeEsj5"> Lecture 3
</a></li>
<li>  <a href="https://sayanmuk.github.io/sayanmuk.github.io/Diagnostics.pdf"> Annotated notes
</a></li>  
  </ul>
 
<!--<ul>
<li> Optional: (video) Christopher Bishop <a href="http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739">Embracing Uncertainty: The New Machine Intelligence</a></li>
<li> Optional: (video) Sam
  Roweis <a href="http://videolectures.net/mlss06tw_roweis_mlpgm/">Machine
    Learning, Probability and Graphical Models, Part 1</a></li>
<li> Optional: (video) Mikaela
  Keller <a href="http://videolectures.net/bootcamp07_keller_bss/">
  Basics of probability and statistics for statistical
  learning</a></li>
<li> Optional: Alan
  Turing <a href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">Computing  Machinery and Intelligence</a></li>
</ul></li>
</ul>-->
<br>
(Aug 26th) Lab 1: <a href="https://github.com/STA521-F19/Lab1">RStudio, Git, & Reproducible EDA using Rmarkdown</a> 
<br>
Homework 2: This is an individual assignment using Github Classroom.  To create your repo for the assignment.<br>
Please see the link in Sakai to the GitHub classroom invitation for the assignment
<br>1) You will be asked to identify your email on the roster  - please do so if you have not already. While the instruction say you can skip this step, please do not. This will link your github username to the roster. We will need that for creating team assignments later.
<br>2) Click on the “accept” button.
<br>3) After the repo is created it will show a link to your repo in the @sta521-F19 organization; click on the link and get started with the instructions in the README file and see the Rmd file.
<br>4) Upload your Rmd file and a pdf to Sakai under assignments by Sept 4 10 am.
<br> 
Please push your final Rmd file and pdf file to the organization repo from your local repo by Sept 4. You should also upload your Rmd and pdf onto Sakai.
<br>   
  <br>  
 <li> (Aug 27th) Transformations:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-4-Transformations/Transformations.pdf">Lecture</a><br>
Influence and Transformations. Read ALR Chapter 8-9 and the Appendix A.12 (4th Edition) and Computing Primer for ALR
</li>
  <ul>
<li> Zoom lecture: <a href="https://duke.zoom.us/rec/share/z-13DLPA7kdOHKvo-EX-A4UQJom-X6a81iNM_qEPyx7yxQ2c6gfO5ZWSX5xp6hYm"> Lecture 4
</a></li>
<li>  <a href="https://sayanmuk.github.io/sayanmuk.github.io/Transformations.pdf"> Annotated notes
</a></li>  
  </ul>
<br>  
 <li> (Sept 1st) Interpretation, Prediction Intervals and Added-Variable Plots:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-6-Interpretation/Interpretation.pdf">Lecture</a><br>
Interpretation, Prediction Intervals and Added-Variable Plots. Read ALR Chapter 3-4 and Computing Primer for ALR.
</li>  
<ul>
<li> Zoom lecture: <a href="https://duke.zoom.us/rec/share/4eJ5L5fM1mlJEqfM0RvCRbEbHL3meaa8gShNqPQFy06kB610Mh3V00IFDIN5zTJn"> Lecture 4
</a></li>  
  <li> R code: <a href=""https://github.com/STA521-F19/Class5.R"> Class 5</a></li>   
<br>
</ul>    
(Sept 2nd) Lab 2: Using github and github classroom with RStudio<br>
<br>    
 <li> (Sept 3rd) Logistic Regression:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-7-Binary-Regression/logistic.pdf">Lecture</a><br>
Binary Regression. Read ESL and/or ISLR Chapter 4 and ALR Chapter 12, GH Chapter 5 for binned plots.
In this lecture, we will describe the use of binary regression when the response variable is binary.
<ul>
<li> Zoom lecture: <a href="https://duke.zoom.us/rec/share/GPtYPsBcR4pMPrgo5IUB79iFtthnxhXjltKV7jSpwh8ElSXdhw03KmdJOckebwpR.ulphFRUgrDEkEJfM"> Lecture 1
</a></li>     
<li>Homework 3: Description on Sakai.
<br>1) This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW3 (same teams as lab). Please work together on the assignment to complete all parts.
<br>2) Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment.
 <br>3) You should also upload your Rmd and pdf onto Sakai (one per group).
<br>4) Upload your Rmd file and a pdf to Sakai under assignments by Sept 11 10 am.
  </li>
    </ul> 
<br>
<li> (Sept 8th) Logistic Regression and Analysis of Deviance:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-8-Analysis-of-Deviance/deviance.pdf">Lecture</a><br>
Analysis of Deviance in Logistic Regression. Read ESL and/or ISLR Chapter 4 and ALR Chapter 12, GH Chapter 5 for binned plots.
In this lecture, we will describe the use of binary regression when the response variable is binary.
  </li>
<br>
(Sept 9th) Lab 4: Logistic Regression, Werker, Teams, and Q&A. Read lab 4 on Sakai for details.
<br>
<br>
<li> (Sept 10th) Modeling Count Data: Poisson & Negative Binomial Models: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-9-Poisson/Poisson.pdf">Lecture</a><br>
In this lecture, we will explore Poisson and Negative Binomial regression for modeling count data.<br>
<br>Homework 4: Description on Sakai.  
<br>This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW4 (same teams as lab). Please work together on the assignment to complete all parts.
<br>Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment (3 points).
<br>You should also upload your Rmd and pdf onto Sakai (one per group) by Sept 18 10 am.  
</li>
<br>
<li> (Sept 15th) Negative Binomial Models and Predictive Checks: <a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-10-NegativeBinomial/negative-binomial.pdf">Lecture</a><br>
Negative Binomial Regression and Predictive Checks. Read GH Chapter 6-8. In this lecture, we will explore Poisson and Negative Binomial regression for modeling count data and explore simulation methods to check for model fit.
</li>
 <br>
(Sept 16th) Lab 5: Predictive Checks & Simulation. Read lab 5 on Sakai for details.
<br>
<br>
<li> (Sept 17th) Model Selection:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-11-Model-Selection/Selection.pdf">Lecture</a>
<br>Model Selection. ISLR Ch 6. ESL Ch 7; Read GH Chapter 6-8. In this lecture, we will introduce AIC and BIC as criteria for selecting models and look at several algorithms for finding the the best model.
</li>
<br>
<li> (Sept 22nd) Cross-Validation:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-12-Resampling/Resampling.pdf">Lecture</a>
<br>Model Assessment and Selection: Resampling ISLR Ch 6. Read GH Chapter 6-8. In this lecture, we will continue to explore model selection using resampling methods to estimate prediction error.
</li>
<br>
(Sept 23rd) Midterm I. Two hour take-home exam on Sakai.
<br>
<br>
<li> (Sept 24th) Coverage:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-12-Resampling/Resampling.pdf">Lecture</a>
<br>Model Assessment and Selection: Resampling ISLR Ch 6. Read GH Chapter 6-8. In this lecture, we will continue to explore model selection using resampling methods to estimate prediction error.
</li>
<br>
<li> (Sept 29th) Bayesian Regression:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-13-Bayes-Reg/bayesreg.pdf">Lecture</a>
<br>Bayesian Regression - Hoff Chapter 9. In this lecture, we will introduce Bayesian methods for estimation in linear regression.
</li>
<br>
(Sept 30th) Lab 6: Simulating Coverage plus Q&A. Read lab 6 on Sakai for details.
<br>
<br>
<li> (Oct 1st) Priors in Bayesian Regression:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-14-Priors/priors.pdf">Lecture</a>
<br>Priors in Bayesian Regression - Hoff Chapter 9. In this lecture, we will introduce Bayesian methods for estimation in linear regression under conjugate priors. We will introduce Jeffreys reference priors and the Zellner g-prior as two default choices.
<br>Homework 5: Description on Sakai.
<br>This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW5 (same teams as lab). Please work together on the assignment to complete all parts.
<br> Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment.
<br> You should also upload your Rmd and pdf onto Sakai (one per group) by Oct 9 10am.  
</li>
<br>
<li> (Oct 6th) Bayesian Variable Selection:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-15-Bayes-VarSel/bayes-varsel.pdf">Lecture</a>
<br>Bayesian Variable Selection - Hoff Chapter 9. In this lecture, we will introduce Bayesian methods for variable selection in linear regression under the g-prior.
</li>
<br>
(Oct 7th) Lab Q&A. 
<br>
<br>
<li> (Oct 8th) Bayesian Model Averaging:
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-16-BMA/bma.pdf">Lecture</a>
<br>Bayesian Model Averaging. In this lecture, we will introduce Bayesian Model Averaging. Rather than selecting a single model for inference, we will use an ensemble of models, weighted by their posterior probabilities.
Supplemental Readings: Chapters 6-8: Introduction to Bayesian Thinking.
 </li>
<br>
<li> (Oct 13th) Ridge Regression
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-17-Ridge/ridge.pdf">Lecture</a>
<br>Ridge Regression. In this lecture, we will introduce Ridge regression from frequentist and Bayesian perspectives as a shrinkage estimator.
<br>Homework 6: Description on Sakai.
<br>This is a team based assignment. On the Classroom Organization on GitHub, you will have a team repo for HW5 (same teams as lab). Please work together on the assignment to complete all parts.
<br> Please push your final Rmd file and pdf file to the team repo from your local repo by the due date to receive full credit on the assignment.
<br> You should also upload your Rmd and pdf onto Sakai (one per group) by Oct 23 10am.  
</li>   
<br>
(Oct 14th) Lab 7: Variable Selection and Bayesian model averaging. Read lab 7 on Sakai for details.
<br>
<br>
<li> (Oct 15th) Shrinkage Estimators
<a href="https://www2.stat.duke.edu/courses/Fall19/sta521/lectures/Lec-17-Ridge/ridge.pdf">Lecture</a>
<br>Lasso and Bayesian Lasso. Lasso and Bayesian lasso Regression. In this lecture, we will introduce Lasso regression from frequentist and Bayesian perspectives as a shrinkage estimator.
</li>   
</body></html>
